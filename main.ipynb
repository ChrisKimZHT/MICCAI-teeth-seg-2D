{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chriskim/anaconda3/envs/miccai2d/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import albumentations as album\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, SequentialLR\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.utils import base, metrics, train\n",
    "from segmentation_models_pytorch.losses import DiceLoss, SoftBCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata_df = pd.read_csv(\"./data.csv\")\n",
    "\n",
    "train_df, test_df = train_test_split(alldata_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transform = album.Compose([\n",
    "    album.HorizontalFlip(),\n",
    "    album.VerticalFlip(),\n",
    "    album.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.9, border_mode=cv2.BORDER_REFLECT),\n",
    "    \n",
    "    album.OneOf([\n",
    "        album.ElasticTransform(p=0.3),\n",
    "        album.MedianBlur(p=0.3),\n",
    "        album.MotionBlur(p=0.3),\n",
    "        album.GaussianBlur(p=0.3),\n",
    "        album.GaussNoise(p=0.3),\n",
    "        album.OpticalDistortion(p=0.3),\n",
    "        album.GridDistortion(p=0.1),\n",
    "    ], p=0.3),\n",
    "\n",
    "    album.OneOf([\n",
    "        album.ColorJitter(p=0.5),\n",
    "        album.HueSaturationValue(15, 25, 0),\n",
    "        album.CLAHE(clip_limit=2),\n",
    "        album.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.75),\n",
    "    ], p=0.3),\n",
    "], p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = [\n",
    "    \"tooth\",\n",
    "    \"background\",\n",
    "]\n",
    "\n",
    "class_rgb_values = [\n",
    "    [255, 255, 255],\n",
    "    [0, 0, 0]\n",
    "]\n",
    "\n",
    "def to_onehot(mask, mask_values):\n",
    "    semantic_map = []\n",
    "    \n",
    "    for colour in mask_values:\n",
    "        equality = np.equal(mask, colour)\n",
    "        class_map = np.all(equality, axis=-1)\n",
    "        semantic_map.append(class_map)\n",
    "\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "    return semantic_map\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "def get_preprocessing(fn=None):\n",
    "    transform = []\n",
    "    if fn:\n",
    "        transform.append(album.Lambda(image=fn))\n",
    "    transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
    "    return album.Compose(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToothDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, preprocessing=None, train=True):\n",
    "        self.image_paths = df[\"image\"].tolist()\n",
    "        self.mask_paths = df[\"mask\"].tolist()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.preprocessing = preprocessing\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            image = cv2.cvtColor(cv2.imread(self.image_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.cvtColor(cv2.imread(self.mask_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mask = to_onehot(mask, class_rgb_values).astype(\"float\")\n",
    "\n",
    "            if self.transform:\n",
    "                sample = self.transform(image=image, mask=mask)\n",
    "                image, mask = sample[\"image\"], sample[\"mask\"]\n",
    "\n",
    "            if self.preprocessing:\n",
    "                sample = self.preprocessing(image=image, mask=mask)\n",
    "                image, mask = sample[\"image\"], sample[\"mask\"]\n",
    "\n",
    "            return image, mask\n",
    "\n",
    "        else:\n",
    "            image = cv2.cvtColor(cv2.imread(self.image_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.transform:\n",
    "                sample = self.transform(image=image)\n",
    "                image = sample[\"image\"]\n",
    "\n",
    "            if self.preprocessing:\n",
    "                sample = self.preprocessing(image=image)\n",
    "                image = sample[\"image\"]\n",
    "\n",
    "            return image, self.mask_paths[idx]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoss(base.Loss):\n",
    "    def __init__(self):\n",
    "        super(MyLoss, self).__init__()\n",
    "\n",
    "        self.diceloss = DiceLoss(mode=\"binary\")\n",
    "        self.binloss = SoftBCEWithLogitsLoss(reduction=\"mean\", smooth_factor=0.1)\n",
    "\n",
    "    def forward(self, output, mask):\n",
    "        dice_loss = self.diceloss(output, mask)\n",
    "        bin_loss = self.binloss(output, mask)\n",
    "\n",
    "        return dice_loss * 0.7 + bin_loss * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = \"mit_b2\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "CLASSES = class_name\n",
    "ACTIVATION = \"sigmoid\"\n",
    "\n",
    "model = smp.MAnet(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    encoder_depth=4,\n",
    "    decoder_channels=(512, 256, 128, 64),\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "train_ds = ToothDataset(\n",
    "    train_df, \n",
    "    transform=training_transform, \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ")\n",
    "\n",
    "test_ds = ToothDataset(\n",
    "    test_df, \n",
    "    transform=None, \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=8)\n",
    "test_dl = DataLoader(test_ds, batch_size=8, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAIN = False\n",
    "INFER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/best_iou_0.9546_at_10.pth\"\n",
    "model = torch.load(model_path, map_location=DEVICE)\n",
    "\n",
    "loss = MyLoss()\n",
    "metrics = [metrics.IoU(threshold=0.5)]\n",
    "optimizer = torch.optim.AdamW([dict(params=model.parameters(), lr=1e-4, weight_decay=0.01)])\n",
    "schedulers = [\n",
    "    CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2, eta_min=1e-6),\n",
    "    CosineAnnealingLR(optimizer=optimizer, T_max=10, eta_min=1e-6)\n",
    "]\n",
    "lr_scheduler = SequentialLR(optimizer, schedulers, milestones=[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = train.TrainEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    best_ephoch = 0\n",
    "    best_iou_score = 0.0\n",
    "    train_logs_list, test_logs_list = [], []\n",
    "\n",
    "    for i in range(0, EPOCHS):\n",
    "        print(f\"Epoch: {i}, Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        train_logs = train_epoch.run(train_dl)\n",
    "        test_logs = valid_epoch.run(test_dl)\n",
    "\n",
    "        train_logs_list.append(train_logs)\n",
    "        test_logs_list.append(test_logs)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        if best_iou_score < test_logs[\"iou_score\"]:\n",
    "            # if best_iou_score != 0:\n",
    "            #     os.remove(f\"model/best_iou_{best_iou_score:.4f}_at_{best_ephoch}.pth\")\n",
    "            #     print(f\"history score {best_iou_score:.4f} model removed!\")\n",
    "\n",
    "            best_ephoch = i\n",
    "            best_iou_score = test_logs[\"iou_score\"]\n",
    "\n",
    "            torch.save(model, f\"model/best_iou_{best_iou_score:.4f}_at_{i}.pth\")\n",
    "\n",
    "            print(f\"best score {best_iou_score:.4f} model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [02:23<00:00, 14.61it/s]\n"
     ]
    }
   ],
   "source": [
    "if INFER:\n",
    "    infer_df = pd.read_csv(\"./unlabelled.csv\")\n",
    "\n",
    "    infer_ds = ToothDataset(\n",
    "        infer_df, \n",
    "        transform=None, \n",
    "        preprocessing=get_preprocessing(preprocessing_fn),\n",
    "        train=False\n",
    "    )\n",
    "\n",
    "    uncertainty = []\n",
    "\n",
    "    for i in tqdm(range(len(infer_ds))):\n",
    "        image, result_path = infer_ds[i]\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_tensor1 = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "            pred_mask1 = model(x_tensor1)\n",
    "            pred_mask1 = pred_mask1[:, 0, :]\n",
    "\n",
    "            x_tensor2 = torch.flip(x_tensor1, [2])\n",
    "            pred_mask2 = model(x_tensor2)\n",
    "            pred_mask2 = torch.flip(pred_mask2, [2])[:, 0, :]\n",
    "\n",
    "            x_tensor3 = torch.flip(x_tensor1, [3])\n",
    "            pred_mask3 = model(x_tensor3)\n",
    "            pred_mask3 = torch.flip(pred_mask3, [3])[:, 0, :]\n",
    "        \n",
    "        pred_mask = (pred_mask1 + pred_mask2 + pred_mask3) / 3.0\n",
    "        prob = pred_mask.cpu().numpy().reshape(320, 640)\n",
    "\n",
    "        uncert = -np.sum(prob * np.log(prob)) / np.sum(prob)\n",
    "        uncertainty.append({\n",
    "            \"path\": result_path,\n",
    "            \"uncertainty\": uncert\n",
    "        })\n",
    "\n",
    "        threshold = 0.5\n",
    "        pred_mask = torch.where(pred_mask >= threshold, torch.tensor(255, dtype=torch.float).to(DEVICE), pred_mask)\n",
    "        pred_mask = torch.where(pred_mask < threshold, torch.tensor(0, dtype=torch.float).to(DEVICE), pred_mask)\n",
    "\n",
    "        out = pred_mask.detach().cpu().numpy().reshape(1, 320, 640)\n",
    "\n",
    "        image = Image.fromarray(out[0].astype(np.uint8))\n",
    "        image.convert(\"1\")\n",
    "\n",
    "        image.save(result_path)\n",
    "\n",
    "    uncertainty = sorted(uncertainty, key=lambda x: x[\"uncertainty\"], reverse=False)\n",
    "    uncertainty_df = pd.DataFrame(uncertainty)\n",
    "    uncertainty_df.to_csv(\"./uncertainty.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_connected_components(binary_image, threshold):\n",
    "    nb_components, output, stats, _ = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
    "    sizes = stats[:, -1]\n",
    "    filtered_image = np.zeros(output.shape)\n",
    "    for i in range(1, nb_components):\n",
    "        if sizes[i] >= threshold:\n",
    "            filtered_image[output == i] = 255\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def process_images_in_directory(input_dir, output_dir, threshold):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for filename in tqdm(os.listdir(input_dir)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            binary_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            filtered_image = filter_small_connected_components(binary_image, threshold).astype(np.bool_)\n",
    "            pil_image = Image.fromarray(filtered_image)\n",
    "            image.convert(\"1\")\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            pil_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_images_in_directory(f\"./infer/label/\", f\"./infer/label/\", 128)\n",
    "process_images_in_directory(f\"./data/unlabelled/fakelabel/\", f\"./data/unlabelled/fakelabel/\", 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miccai2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
